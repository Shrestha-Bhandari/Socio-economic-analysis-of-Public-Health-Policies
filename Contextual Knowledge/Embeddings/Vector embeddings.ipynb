{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75da9616-42a0-4388-9e43-1f79daa47cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (4.0.2)\n",
      "Requirement already satisfied: faiss-cpu in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (1.10.0)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from sentence-transformers) (4.51.0)\n",
      "Requirement already satisfied: tqdm in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from sentence-transformers) (0.30.1)\n",
      "Requirement already satisfied: Pillow in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from sentence-transformers) (4.13.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from faiss-cpu) (2.2.4)\n",
      "Requirement already satisfied: packaging in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: filelock in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: setuptools in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/envs/my_virtual_environment/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Using cached pandas-2.2.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers faiss-cpu pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7cc55b43-7a97-4eaf-9e4e-72b985fa08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "747fc69b-88a6-4ac4-8a56-b6db50201044",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    'Pdf/dataset (1).json',\n",
    "    'Pdf/Merged Q& A data.json',\n",
    "    'Pdf/public_health_batch_2_51_to_100.json',\n",
    "    'Pdf/public_health_batch_3_101_to_150.json',\n",
    "    'Pdf/public_health_batch_4_next_50.json',\n",
    "    'Pdf/public_health_batch_5_next_50.json',\n",
    "    'Pdf/public_health_batch_6_statewise_200_to_249.json',\n",
    "    'Pdf/public_health_batch_7_statewise_250_to_299.json',\n",
    "    'Pdf/public_health_batch_9_statewise_350_to_399.json',\n",
    "    'Pdf/public_health_batch_10_countywise_400_to_449.json',\n",
    "    'Pdf/public_health_batch_11_countywise_450_to_499.json',\n",
    "    'Pdf/public_health_batch_12_countywise_500_to_549.json',\n",
    "    'Pdf/public_health_batch_13_countywise_550_to_599.json',\n",
    "    'Pdf/public_health_socioeconomic_dataset.json',\n",
    "    'Pdf/testing.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b8e034a-3d60-43d6-9b1c-852113012422",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = \"vector_index.faiss\"\n",
    "metadata_file = \"vector_metadata.json\"\n",
    "eval_query_file = \"evaluation_queries.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6abfc740-e644-4eeb-974e-7ce2ee0137bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66333cd2-a236-4cba-b7c9-bc84b74ecadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_file(path: str) -> List[Dict]:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    texts = []\n",
    "    if isinstance(data, dict) and \"entries\" in data:\n",
    "        for entry in data[\"entries\"]:\n",
    "            content = f\"Q: {entry.get('question')} A: {entry.get('answer')}\"\n",
    "            texts.append({\"text\": content, \"source\": os.path.basename(path)})\n",
    "    elif isinstance(data, dict):\n",
    "        for doc in data.values():\n",
    "            content = ' '.join([\n",
    "                doc.get(\"title\", \"\"),\n",
    "                doc.get(\"abstract\", \"\"),\n",
    "                doc.get(\"summary\", \"\"),\n",
    "                doc.get(\"key_findings\", \"\"),\n",
    "                doc.get(\"conclusion\", \"\")\n",
    "            ])\n",
    "            texts.append({\"text\": content, \"source\": os.path.basename(path)})\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            content = ' '.join([\n",
    "                item.get(\"socio_economic_indicator\", \"\"),\n",
    "                item.get(\"summary\", \"\"),\n",
    "                item.get(\"analysis\", \"\"),\n",
    "                item.get(\"statistical_findings\", \"\")\n",
    "            ])\n",
    "            texts.append({\"text\": content, \"source\": os.path.basename(path)})\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "776c67bc-bbd6-414a-9d63-63d376dca27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 1441 documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777f508e8d614cafbd61667053a80622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = [doc[\"text\"] for doc in documents]\n",
    "print(f\"Generating embeddings for {len(texts)} documents...\")\n",
    "embeddings = model.encode(texts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73ee0663-6039-4840-9aef-68a72352c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings))\n",
    "faiss.write_index(index, embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2de57659-4c33-4292-afb0-507bdf4383f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(metadata_file, \"w\") as f:\n",
    "    json.dump(documents, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "401c7d4a-808b-4570-a094-74309bd0ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(index, documents, model, eval_queries, k=5):\n",
    "    mrr_total, precision_total, recall_total = 0, 0, 0\n",
    "    num_queries = len(eval_queries)\n",
    "\n",
    "    for item in tqdm(eval_queries):\n",
    "        query = item[\"query\"]\n",
    "        relevant_ids = set(item[\"relevant_doc_ids\"])\n",
    "        query_embedding = model.encode([query])\n",
    "        distances, indices = index.search(np.array(query_embedding), k)\n",
    "        retrieved_set = set(indices[0])\n",
    "\n",
    "        # MRR\n",
    "        mrr = 0\n",
    "        for rank, idx in enumerate(indices[0], 1):\n",
    "            if idx in relevant_ids:\n",
    "                mrr = 1 / rank\n",
    "                break\n",
    "        mrr_total += mrr\n",
    "\n",
    "        # Precision & Recall\n",
    "        match = relevant_ids.intersection(retrieved_set)\n",
    "        precision_total += len(match) / k\n",
    "        recall_total += len(match) / len(relevant_ids) if relevant_ids else 0\n",
    "\n",
    "    print(f\"\\nðŸ“Š Evaluation Summary (Top-{k}):\")\n",
    "    print(f\" - MRR: {mrr_total / num_queries:.4f}\")\n",
    "    print(f\" - Precision@{k}: {precision_total / num_queries:.4f}\")\n",
    "    print(f\" - Recall@{k}: {recall_total / num_queries:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff79fdb5-7a5f-4dba-a498-a80977fb3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_queries = [\n",
    "    \"What is the relationship between education and obesity?\",\n",
    "    \"How does housing influence respiratory conditions?\",\n",
    "    \"How does income inequality affect life expectancy?\",\n",
    "    \"What reforms were made to Connecticutâ€™s education system?\",\n",
    "    \"What is the impact of curriculum change on student learning?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "457ce365-a2eb-4948-a961-154354ed7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_generate_eval_queries(queries, model, index, documents, top_k=1):\n",
    "    eval_data = []\n",
    "\n",
    "    for query in queries:\n",
    "        query_embedding = model.encode([query])\n",
    "        distances, indices = index.search(np.array(query_embedding), top_k)\n",
    "\n",
    "        relevant_doc_ids = indices[0].tolist()\n",
    "        eval_data.append({\n",
    "            \"query\": query,\n",
    "            \"relevant_doc_ids\": relevant_doc_ids\n",
    "        })\n",
    "\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        for i in relevant_doc_ids:\n",
    "            print(f\"Matched doc #{i}: {documents[i]['text'][:200]}\")\n",
    "\n",
    "    with open(\"evaluation_queries.json\", \"w\") as f:\n",
    "        json.dump(eval_data, f, indent=2)\n",
    "    print(\"\\nevaluation_queries.json generated with top-{top_k} results for each query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9c83335b-d930-4039-8cbb-e439329e4a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What is the relationship between education and obesity?\n",
      "Matched doc #202: Q: What impact does educational attainment have on obesity rates in the USA? A: Higher educational attainment is associated with lower obesity rates in the USA. Adults with a college degree have an ob\n",
      "\n",
      "Query: How does housing influence respiratory conditions?\n",
      "Matched doc #206: Q: What role does housing instability play in respiratory illness rates in the USA? A: Housing instability, such as frequent moves or overcrowding, increases respiratory illness rates by 15-20%. Poor \n",
      "\n",
      "Query: How does income inequality affect life expectancy?\n",
      "Matched doc #201: Q: How does income inequality, as measured by the Gini coefficient, correlate with life expectancy in the United States? A: Income inequality, measured by the Gini coefficient, shows a negative correl\n",
      "\n",
      "Query: What reforms were made to Connecticutâ€™s education system?\n",
      "Matched doc #9: Curriculum Development in Connecticut: A Strategy for Educational Improvement This report articulates a broad vision for curriculum reform in Connecticut. It identifies the long-term societal changes \n",
      "\n",
      "Query: What is the impact of curriculum change on student learning?\n",
      "Matched doc #9: Curriculum Development in Connecticut: A Strategy for Educational Improvement This report articulates a broad vision for curriculum reform in Connecticut. It identifies the long-term societal changes \n",
      "\n",
      "evaluation_queries.json generated with top-{top_k} results for each query.\n"
     ]
    }
   ],
   "source": [
    "auto_generate_eval_queries(raw_queries, model, index, documents, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf2c8c-be4c-4bdf-8228-0c0a56949735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e7b5c-d5f6-4e4e-97c6-c7cf2b30bcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "deb1b2a6-47e3-4d9a-aac1-d197a98180a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 54.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluation Summary (Top-5):\n",
      " - MRR: 1.0000\n",
      " - Precision@5: 0.2000\n",
      " - Recall@5: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(eval_query_file):\n",
    "    with open(eval_query_file, 'r') as f:\n",
    "        eval_queries = json.load(f)\n",
    "    index = faiss.read_index(embedding_file)\n",
    "    evaluate(index, documents, model, json.load(open(\"evaluation_queries.json\")), k=5)\n",
    "else:\n",
    "    print(f\"No evaluation file found at `{eval_query_file}`. Skipping evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38845dc-6e5b-476f-b6c5-1a196bd0f4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
