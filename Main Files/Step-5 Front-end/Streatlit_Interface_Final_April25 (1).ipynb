{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit transformers huggingface_hub peft torch datetime"
      ],
      "metadata": {
        "id": "Y1vy-z1-8VBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_file.py\n",
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from huggingface_hub import login\n",
        "from peft import PeftModel, PeftConfig\n",
        "from datetime import datetime\n",
        "import torch\n",
        "\n",
        "# Set up Hugging Face token directly\n",
        "HF_TOKEN = \"\"  # Replace with your Hugging Face token\n",
        "MODEL_NAME = \"iyashnayi/SocioLens-llama-3.2-3B\"\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "# Configure page layout\n",
        "st.set_page_config(page_title=\"SocioLens\", layout=\"wide\")\n",
        "\n",
        "# Custom styling\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "        /* Sidebar styling */\n",
        "        section[data-testid=\"stSidebar\"] {\n",
        "            background-color: #1C2526;\n",
        "            color: #FFFFFF;\n",
        "            display: flex;\n",
        "            flex-direction: column;\n",
        "        }\n",
        "        /* Main pane styling */\n",
        "        .main {\n",
        "            background-color: #000000;\n",
        "            font-family: 'Inter', sans-serif;\n",
        "            color: #FFFFFF;\n",
        "            position: relative;\n",
        "            min-height: 100vh;\n",
        "        }\n",
        "        /* Header container */\n",
        "        .header-container {\n",
        "            display: flex;\n",
        "            justify-content: center;\n",
        "            align-items: center;\n",
        "            margin-top: 2rem;\n",
        "            margin-bottom: 1rem;\n",
        "        }\n",
        "        /* Title styling */\n",
        "        .header-logo {\n",
        "            font-size: 3rem;\n",
        "            font-weight: bold;\n",
        "            color: #FF9F1C;\n",
        "            font-family: 'Inter', sans-serif;\n",
        "            letter-spacing: -1px;\n",
        "            margin-bottom: 0.5rem;\n",
        "        }\n",
        "        /* Subtitle styling */\n",
        "        .header-subtitle {\n",
        "            font-size: 1.2rem;\n",
        "            color: #FF9F1C;\n",
        "            font-style: italic;\n",
        "            text-align: center;\n",
        "            opacity: 0;\n",
        "            animation: fadeIn 1.5s forwards;\n",
        "            animation-delay: 0.5s;\n",
        "        }\n",
        "        @keyframes fadeIn {\n",
        "            from { opacity: 0; transform: translateY(10px); }\n",
        "            to { opacity: 1; transform: translateY(0); }\n",
        "        }\n",
        "        /* Button styling */\n",
        "        .stButton>button {\n",
        "            background-color: #444444;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 6px;\n",
        "            padding: 0.5rem 1rem;\n",
        "            font-weight: 500;\n",
        "        }\n",
        "        .stButton>button:hover {\n",
        "            background-color: #555555;\n",
        "        }\n",
        "        /* Chat message styling */\n",
        "        .stChatMessage {\n",
        "            background-color: #2D2D2D;\n",
        "            border-radius: 10px;\n",
        "            padding: 15px;\n",
        "            margin-bottom: 15px;\n",
        "            border-left: 3px solid #FF9F1C;\n",
        "            color: #FFFFFF;\n",
        "        }\n",
        "        .chat-area {\n",
        "            padding-bottom: 80px;\n",
        "        }\n",
        "        .sidebar-content {\n",
        "            flex: 1;\n",
        "        }\n",
        "        .sidebar-upload {\n",
        "            margin-top: auto;\n",
        "            padding-bottom: 20px;\n",
        "            border-top: 1px solid #444444;\n",
        "            padding-top: 15px;\n",
        "        }\n",
        "        .stSidebar div[data-testid=\"stFileUploader\"] {\n",
        "            background-color: #2D2D2D;\n",
        "            border-radius: 8px;\n",
        "            padding: 10px;\n",
        "            margin-top: 10px;\n",
        "        }\n",
        "        .stSidebar div[data-testid=\"stFileUploader\"] label {\n",
        "            color: #FFFFFF;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        .upload-button {\n",
        "            width: 100%;\n",
        "            background-color: #444444;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 6px;\n",
        "            padding: 8px;\n",
        "            font-weight: 500;\n",
        "            margin-top: 5px;\n",
        "            cursor: pointer;\n",
        "            text-align: center;\n",
        "        }\n",
        "        .sidebar-header {\n",
        "            color: #FFFFFF;\n",
        "            font-weight: 600;\n",
        "            margin-top: 1rem;\n",
        "        }\n",
        "        .element-container:has(footer) {display: none;}\n",
        "        #MainMenu {visibility: hidden;}\n",
        "        header {visibility: hidden;}\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Header\n",
        "st.markdown(\"\"\"\n",
        "    <div class=\"header-container\">\n",
        "        <div>\n",
        "            <div class=\"header-logo\">💬 SocioLens</div>\n",
        "            <div class=\"header-subtitle\">Your Public Policy Analysis Assistant</div>\n",
        "        </div>\n",
        "    </div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.markdown(\"<style>h1 {display: none;}</style>\", unsafe_allow_html=True)\n",
        "\n",
        "# Define policy analysis & greetings prompt templates\n",
        "prompt_templates = {\n",
        "    \"analysis\": \"\"\"You are SocioLens — a data-driven and experienced public policy analyst specializing in social impact, governance, and economic equity.\n",
        "\n",
        "Analyze the following policy issue:\n",
        "{query}\n",
        "\n",
        "Approach:\n",
        "1. **Executive Summary** – Provide a 1-2 sentence summary of the issue and key insight.\n",
        "2. **Context** – Briefly situate the issue in historical, social, or economic terms.\n",
        "3. **Key Factors** – Identify driving forces, affected populations, and relevant data indicators.\n",
        "4. **Stakeholder Impact** – Who gains, who bears the cost, and what power dynamics exist?\n",
        "5. **Evidence-Based Recommendations** – Provide 2-3 clear policy options with pros/cons.\n",
        "6. **Implementation Notes** – Mention feasibility, barriers, or trade-offs if applicable.\n",
        "\n",
        "Keep language clear, neutral, and grounded in data. Highlight uncertainties or assumptions explicitly.\"\"\",\n",
        "\n",
        "    \"comparative\": \"\"\"You are SocioLens — a veteran public policy analyst skilled in comparative frameworks and stakeholder-centered evaluation.\n",
        "\n",
        "Compare the following policy approaches:\n",
        "{query}\n",
        "\n",
        "Structure your response as follows:\n",
        "1. **Policy Snapshot** – Briefly outline each approach in 1–2 sentences.\n",
        "2. **Evaluation Criteria** – Use 3-4 key axes: effectiveness, cost, equity, and implementation risk.\n",
        "3. **Stakeholder Analysis** – Discuss who benefits/loses under each option.\n",
        "4. **Evidence** – Reference real-world data, cases, or trends if possible.\n",
        "5. **Conclusion** – State which policy fits best in what scenario, and note any hybrid strategies.\n",
        "\n",
        "Maintain neutrality, present pros/cons clearly, and surface any political or ethical tensions.\"\"\",\n",
        "\n",
        "    \"forecast\": \"\"\"You are SocioLens — an experienced policy analyst focused on scenario modeling and systemic forecasting.\n",
        "\n",
        "Forecast the outcomes of the following policy change:\n",
        "{query}\n",
        "\n",
        "Organize your response as follows:\n",
        "1. **Short-Term Outlook (1–2 yrs)** – Immediate implementation effects and likely reactions.\n",
        "2. **Medium-Term Outlook (3–5 yrs)** – Shifts in behavior, cost structures, or demographics.\n",
        "3. **Long-Term Effects (5+ yrs)** – Institutional, environmental, or generational consequences.\n",
        "4. **Unintended Consequences** – Identify risks, externalities, or vulnerable populations.\n",
        "5. **Confidence Levels** – Indicate high/medium/low certainty in predictions.\n",
        "6. **Monitoring Recommendations** – Suggest what metrics or signals should be tracked.\n",
        "\n",
        "Use a tone that is cautious, analytic, and contingency-aware. Point out where assumptions drive outcomes.\"\"\",\n",
        "\n",
        "    \"greeting\": \"\"\"You are SocioLens — a friendly and welcoming public policy assistant.\n",
        "\n",
        "The user says: \"{query}\"\n",
        "\n",
        "Respond with a warm greeting and ask how you can assist, without any policy analysis.\"\"\"\n",
        "}\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    peft_model_id = MODEL_NAME\n",
        "    config = PeftConfig.from_pretrained(peft_model_id)\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        config.base_model_name_or_path,\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    model = PeftModel.from_pretrained(base_model, peft_model_id)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "    return model, tokenizer\n",
        "\n",
        "model, tokenizer = load_model()\n",
        "\n",
        "# Session state setup\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = {}\n",
        "if \"uploaded_file\" not in st.session_state:\n",
        "    st.session_state.uploaded_file = None\n",
        "if \"analysis_mode\" not in st.session_state:\n",
        "    st.session_state.analysis_mode = \"analysis\"\n",
        "\n",
        "# Sidebar UI\n",
        "with st.sidebar:\n",
        "    st.markdown('<div class=\"sidebar-content\">', unsafe_allow_html=True)\n",
        "    st.markdown('<h3 class=\"sidebar-header\">📊 Analysis Mode</h3>', unsafe_allow_html=True)\n",
        "    analysis_mode = st.radio(\n",
        "        \"Select analysis type:\",\n",
        "        options=[\"General Analysis\", \"Comparative Analysis\", \"Impact Forecast\"],\n",
        "        index=0,\n",
        "    )\n",
        "    mode_mapping = {\n",
        "        \"General Analysis\": \"analysis\",\n",
        "        \"Comparative Analysis\": \"comparative\",\n",
        "        \"Impact Forecast\": \"forecast\"\n",
        "    }\n",
        "    st.session_state.analysis_mode = mode_mapping[analysis_mode]\n",
        "\n",
        "    st.markdown('<h3 class=\"sidebar-header\">📁 Chat Options</h3>', unsafe_allow_html=True)\n",
        "    if st.button(\"🆕 New Chat\"):\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        if st.session_state.messages:\n",
        "            st.session_state.chat_history[timestamp] = st.session_state.messages\n",
        "        st.session_state.messages = []\n",
        "        st.rerun()\n",
        "\n",
        "    st.markdown('<h3 class=\"sidebar-header\">📜 Chat History</h3>', unsafe_allow_html=True)\n",
        "    for k in reversed(list(st.session_state.chat_history.keys())):\n",
        "        if st.button(k):\n",
        "            st.session_state.messages = st.session_state.chat_history[k]\n",
        "            st.rerun()\n",
        "    st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown('<div class=\"sidebar-upload\">', unsafe_allow_html=True)\n",
        "    st.markdown('<h3 class=\"sidebar-header\">📎 Upload Policy Documents</h3>', unsafe_allow_html=True)\n",
        "    uploaded_file = st.file_uploader(\"Upload document to analyze\", type=[\"txt\", \"pdf\", \"docx\"])\n",
        "    if uploaded_file:\n",
        "        st.session_state.uploaded_file = uploaded_file\n",
        "        st.markdown(f'<p style=\"color: white;\">Uploaded: {uploaded_file.name}</p>', unsafe_allow_html=True)\n",
        "        file_details = {\n",
        "            \"Filename\": uploaded_file.name,\n",
        "            \"File size\": f\"{uploaded_file.size / 1024:.2f} KB\"\n",
        "        }\n",
        "        st.markdown('<p style=\"color: white;\">File Details:</p>', unsafe_allow_html=True)\n",
        "        for key, value in file_details.items():\n",
        "            st.markdown(f'<p style=\"color: white;\">- <b>{key}:</b> {value}</p>', unsafe_allow_html=True)\n",
        "    st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "# Chat area\n",
        "chat_area = st.container()\n",
        "with chat_area:\n",
        "    st.markdown('<div class=\"chat-area\">', unsafe_allow_html=True)\n",
        "    for msg in st.session_state.messages:\n",
        "        with st.chat_message(msg[\"role\"]):\n",
        "            st.markdown(f'<p style=\"color: white;\">{msg[\"content\"]}</p>', unsafe_allow_html=True)\n",
        "    st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "# Example prompts\n",
        "with st.expander(\"💡 Example prompts for your selected analysis mode\"):\n",
        "    if st.session_state.analysis_mode == \"analysis\":\n",
        "        st.markdown(\"\"\"\n",
        "        - Analyze the impact of increasing minimum wage to $15/hour on small businesses\n",
        "        - What are the implications of extending public transit to suburban areas?\n",
        "        - Evaluate the effectiveness of tax incentives for renewable energy adoption\n",
        "        \"\"\")\n",
        "    elif st.session_state.analysis_mode == \"comparative\":\n",
        "        st.markdown(\"\"\"\n",
        "        - Compare voucher-based and public housing approaches to affordable housing\n",
        "        - Contrast carbon tax vs. cap-and-trade systems for reducing emissions\n",
        "        - Compare merit-based vs. need-based scholarship programs for higher education\n",
        "        \"\"\")\n",
        "    else:\n",
        "        st.markdown(\"\"\"\n",
        "        - Forecast the economic impact of implementing a four-day workweek\n",
        "        - What would be the long-term effects of universal basic income?\n",
        "        - Project the outcomes of reducing police department funding by 10%\n",
        "        \"\"\")\n",
        "\n",
        "# Chat input\n",
        "if prompt := st.chat_input(\"Type your policy question...\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    st.rerun()\n",
        "\n",
        "# Process assistant response\n",
        "if st.session_state.messages and st.session_state.messages[-1][\"role\"] == \"user\":\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        with st.spinner(\"Generating response...\"):\n",
        "            user_prompt = st.session_state.messages[-1][\"content\"]\n",
        "            # Detect simple greetings\n",
        "            greetings = [\"hi\", \"hello\", \"hey\", \"good morning\", \"good afternoon\", \"good evening\"]\n",
        "            is_greeting = user_prompt.strip().lower() in greetings\n",
        "\n",
        "            # Choose appropriate template\n",
        "            if is_greeting:\n",
        "                selected_template = prompt_templates[\"greeting\"]\n",
        "                max_tokens = 50\n",
        "            else:\n",
        "                selected_template = prompt_templates[st.session_state.analysis_mode]\n",
        "                max_tokens = 300\n",
        "\n",
        "            # Format prompt\n",
        "            formatted_prompt = selected_template.format(query=user_prompt)\n",
        "\n",
        "            # Append uploaded document context if any\n",
        "            if st.session_state.uploaded_file and not is_greeting:\n",
        "                try:\n",
        "                    file_text = st.session_state.uploaded_file.getvalue().decode(\"utf-8\")\n",
        "                    formatted_prompt += f\"\\n\\nPolicy document context:\\n{file_text}\"\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error reading file: {e}\")\n",
        "\n",
        "            # Generate model output\n",
        "            inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(model.device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model.generate(**inputs, max_new_tokens=max_tokens)\n",
        "            reply = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Display & store\n",
        "            st.markdown(f'<p style=\"color: white;\">{reply}</p>', unsafe_allow_html=True)\n",
        "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": reply})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRvweCpN_dk2",
        "outputId": "07d1e2cf-61c5-4295-a4f9-5568c1c3634d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing my_file.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install streamlit\n",
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "id": "U8womfnbDF45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995d389c-fbac-4a18-f931-a3c691cea393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill all existing tunnels\n",
        "ngrok.kill()\n"
      ],
      "metadata": {
        "id": "_rlYf_b9DEgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Authenticate ngrok with your token\n",
        "!ngrok authtoken \" \"  # Replace this with your actual ngrok token\n",
        "\n",
        "\n",
        "\n",
        "# Run Streamlit app in the background and expose it via ngrok\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Run Streamlit app (background execution)\n",
        "os.system(\"streamlit run my_file.py &\")\n",
        "\n",
        "# Open ngrok tunnel for the Streamlit app (exposing port 8501)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is running at: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws5yo2E0-OP0",
        "outputId": "6aa48bbb-32ff-42f2-8fcb-fd5aa02ac1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Streamlit app is running at: NgrokTunnel: \"https://0766-34-143-135-233.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-kAuGw_J6sMI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}