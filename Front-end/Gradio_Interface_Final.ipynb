{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j8Rg5J9BH1QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To patch in model from Hugging Face"
      ],
      "metadata": {
        "id": "xEu_W65TH9FS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wEA3XkDHy3j"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers\n",
        "\n",
        "import time\n",
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model and tokenizer from Hugging Face\n",
        "model_id = \"your-username/your-model-name\"  # Replace with your model ID\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def chat_with_model(message, history, uploaded_file):\n",
        "    # Construct the conversation history as a prompt\n",
        "    prompt = \"\"\n",
        "    for entry in history:\n",
        "        user_msg = entry[\"user\"] if \"user\" in entry else \"\"\n",
        "        bot_msg = entry[\"assistant\"] if \"assistant\" in entry else \"\"\n",
        "        prompt += f\"User: {user_msg}\\nAssistant: {bot_msg}\\n\"\n",
        "    prompt += f\"User: {message}\\nAssistant: \"\n",
        "\n",
        "    # If a file is uploaded, append its name to the prompt\n",
        "    if uploaded_file:\n",
        "        file_name = uploaded_file.name.split('/')[-1]\n",
        "        prompt += f\"[Uploaded file: {file_name}]\\n\"\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Generate a response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_length=512,\n",
        "            num_return_sequences=1,\n",
        "            do_sample=True,\n",
        "            top_p=0.95,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "    # Decode the response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract the assistant's response (remove the prompt part)\n",
        "    response = response[len(prompt):].strip()\n",
        "\n",
        "    # Yield the response\n",
        "    yield response\n",
        "\n",
        "custom_css = \"\"\"\n",
        "body {\n",
        "    background-color: #0f172a;\n",
        "    color: white;\n",
        "    font-family: 'Segoe UI', sans-serif;\n",
        "}\n",
        "\n",
        ".gradio-container {\n",
        "    background-color: #0f172a;\n",
        "}\n",
        "\n",
        ".header-text {\n",
        "    text-align: center;\n",
        "    padding: 20px 0;\n",
        "    font-size: 24px;\n",
        "    color: white;\n",
        "}\n",
        "\n",
        ".message.user {\n",
        "    background-color: #334155 !important;\n",
        "    color: white !important;\n",
        "    border-radius: 15px !important;\n",
        "    padding: 8px 12px;\n",
        "}\n",
        "\n",
        ".message.bot {\n",
        "    background-color: #1e293b !important;\n",
        "    color: white !important;\n",
        "    border-radius: 15px !important;\n",
        "    padding: 8px 12px;\n",
        "}\n",
        "\n",
        ".gr-textbox {\n",
        "    background-color: #1e293b !important;\n",
        "    color: white !important;\n",
        "    border: 1px solid #334155 !important;\n",
        "}\n",
        "\n",
        ".gr-button {\n",
        "    background-color: #334155 !important;\n",
        "    color: white !important;\n",
        "    border: none !important;\n",
        "}\n",
        "\n",
        ".gr-button:hover {\n",
        "    background-color: #475569 !important;\n",
        "}\n",
        "\n",
        ".upload-button {\n",
        "    background-color: #334155 !important;\n",
        "    color: white !important;\n",
        "    border: none !important;\n",
        "    padding: 8px 16px !important;\n",
        "    width: 150px !important;\n",
        "    height: 40px !important;\n",
        "    display: flex !important;\n",
        "    align-items: center !important;\n",
        "    justify-content: center !important;\n",
        "    font-size: 14px !important;\n",
        "    margin-top: 10px !important;\n",
        "}\n",
        "\n",
        ".upload-button:hover {\n",
        "    background-color: #475569 !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create the interface with a custom header\n",
        "with gr.Blocks(css=custom_css) as demo:\n",
        "    gr.Markdown(\n",
        "        '<div class=\"header-text\">How can I help you today? I\\'m SocioLens.</div>'\n",
        "    )\n",
        "\n",
        "    # Create the upload button but don't render it yet\n",
        "    upload_button = gr.UploadButton(\n",
        "        label=\"Upload File\",\n",
        "        render=False,\n",
        "        elem_classes=\"upload-button\",\n",
        "        file_count=\"single\"\n",
        "    )\n",
        "\n",
        "    # Use ChatInterface with the upload button as an additional input\n",
        "    gr.ChatInterface(\n",
        "        fn=chat_with_model,\n",
        "        type=\"messages\",\n",
        "        flagging_mode=\"manual\",\n",
        "        flagging_options=[\"Like\", \"Spam\", \"Inappropriate\", \"Other\"],\n",
        "        save_history=True,\n",
        "        additional_inputs=[upload_button]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rNc0mcGxIEt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading and Using a Fine-Tuned Model from Google Drive**"
      ],
      "metadata": {
        "id": "D8Tux9tCIHCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install transformers\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import time\n",
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Path to your fine-tuned model folder in Google Drive\n",
        "model_path = \"/content/drive/MyDrive/path/to/your/model/folder\"  # Replace with your model path\n",
        "\n",
        "# Load the tokenizer and model from Google Drive\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def chat_with_model(message, history, uploaded_file):\n",
        "    # Construct the conversation history as a prompt\n",
        "    prompt = \"\"\n",
        "    for entry in history:\n",
        "        user_msg = entry[\"user\"] if \"user\" in entry else \"\"\n",
        "        bot_msg = entry[\"assistant\"] if \"assistant\" in entry else \"\"\n",
        "        prompt += f\"User: {user_msg}\\nAssistant: {bot_msg}\\n\"\n",
        "    prompt += f\"User: {message}\\nAssistant: \"\n",
        "\n",
        "    # If a file is uploaded, append its name to the prompt\n",
        "    if uploaded_file:\n",
        "        file_name = uploaded_file.name.split('/')[-1]\n",
        "        prompt += f\"[Uploaded file: {file_name}]\\n\"\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Generate a response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_length=512,\n",
        "            num_return_sequences=1,\n",
        "            do_sample=True,\n",
        "            top_p=0.95,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "    # Decode the response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract the assistant's response (remove the prompt part)\n",
        "    response = response[len(prompt):].strip()\n",
        "\n",
        "    # Yield the response\n",
        "    yield response\n",
        "\n",
        "custom_css = \"\"\"\n",
        "body {\n",
        "    background-color: #0f172a;\n",
        "    color: white;\n",
        "    font-family: 'Segoe UI', sans-serif;\n",
        "}\n",
        "\n",
        ".gradio-container {\n",
        "    background-color: #0f172a;\n",
        "}\n",
        "\n",
        ".header-text {\n",
        "    text-align: center;\n",
        "    padding: 20px 0;\n",
        "    font-size: 24px;\n",
        "    color: white;\n",
        "}\n",
        "\n",
        ".message.user {\n",
        "    background-color: #334155 !important;\n",
        "    color: white !important;\n",
        "    border-radius: 15px !important;\n",
        "    padding: 8px 12px;\n",
        "}\n",
        "\n",
        ".message.bot {\n",
        "    background-color: #1e293b !important;\n",
        "    color: white !important;\n",
        "    border-radius: 15px !important;\n",
        "    padding: 8px 12px;\n",
        "}\n",
        "\n",
        ".gr-textbox {\n",
        "    background-color: #1e293b !important;\n",
        "    color: white !important;\n",
        "    border: 1px solid #334155 !important;\n",
        "}\n",
        "\n",
        ".gr-button {\n",
        "    background-color: #334155 !important;\n",
        "    color: white !important;\n",
        "    border: none !important;\n",
        "}\n",
        "\n",
        ".gr-button:hover {\n",
        "    background-color: #475569 !important;\n",
        "}\n",
        "\n",
        ".upload-button {\n",
        "    background-color: #334155 !important;\n",
        "    color: white !important;\n",
        "    border: none !important;\n",
        "    padding: 8px 16px !important;\n",
        "    width: 150px !important;\n",
        "    height: 40px !important;\n",
        "    display: flex !important;\n",
        "    align-items: center !important;\n",
        "    justify-content: center !important;\n",
        "    font-size: 14px !important;\n",
        "    margin-top: 10px !important;\n",
        "}\n",
        "\n",
        ".upload-button:hover {\n",
        "    background-color: #475569 !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create the interface with a custom header\n",
        "with gr.Blocks(css=custom_css) as demo:\n",
        "    gr.Markdown(\n",
        "        '<div class=\"header-text\">How can I help you today? I\\'m SocioLens.</div>'\n",
        "    )\n",
        "\n",
        "    # Create the upload button but don't render it yet\n",
        "    upload_button = gr.UploadButton(\n",
        "        label=\"Upload File\",\n",
        "        render=False,\n",
        "        elem_classes=\"upload-button\",\n",
        "        file_count=\"single\"\n",
        "    )\n",
        "\n",
        "    # Use ChatInterface with the upload button as an additional input\n",
        "    gr.ChatInterface(\n",
        "        fn=chat_with_model,\n",
        "        type=\"messages\",\n",
        "        flagging_mode=\"manual\",\n",
        "        flagging_options=[\"Like\", \"Spam\", \"Inappropriate\", \"Other\"],\n",
        "        save_history=True,\n",
        "        additional_inputs=[upload_button]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "id": "I_KJeWQGIEqY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}